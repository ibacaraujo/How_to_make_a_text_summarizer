{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from RNN_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length in numbers of characters: 709\n",
      "['part', 'Europan', 'A', \"'n\", 'adapted', ',', 'additional', 'composer', 'progresses', 'freely', ')', 'There', 'on', 'using', 'development', '2010', 'the', 'Honjou', 'camp', 'during', 'through', 'battle', 'or', 'They', 'skills', '(', 'animated', 'over', 'features', 'unit', 'an', 'Takeshi', 'forces', 'perform', 'War', 'individual', 'difficulty', 'partially', 'off', 'script', 'if', 'getting', 'pitted', 'for', 'be', 'Potential', 'players', 'growth', 'them', 'into', 'Azure', 'rest', 'with', 'carrying', 'previous', \"'s\", 'translation', 'year', 'The', 'divided', 'units', 'against', 'Stories', 'Personal', 'Senjō', 'Employing', 'is', 'forgiving', 'of', 'heroines', 'BliTZ', 'it', 'During', 'Unrecorded', 'Valkyria', 'large', 'operations', 'and', 'control', 'Ozawa', 'Raita', 'carried', 'Outside', 'linear', 'being', 'praised', 'unique', 'episodes', 'released', 'replayed', 'Chronicles', 'outside', 'can', 'gameplay', 'map', \"'\", 'time', 'single', 'those', 'system', 'was', 'knocked', 'innate', 'nation', 'who', 'handled', 'more', 'developed', 'main', 'adjustments', 'related', 'Gauge', 'out', 'PlayStation', 'scanned', 'also', 'route', 'that', 'Up', 'selected', 'down', 'Calamaty', 'voiced', 'bubbles', 'movement', '3', 'tactical', 'franchise', 'speaking', 'director', 'playing', 'edition', 'moves', 'turn', 'its', 'completion', 'are', 'work', 'theme', 'no', 'having', 'Revolution', 'positive', 'varies', 'option', 'predecessors', 'Gameplay', 'fan', 'perspective', 'writers', 'although', '戦場のヴァルキュリア3', 'panels', 'person', 'real', 'Raven', 'western', 'retained', 'points', 'like', 'III', 'in', 'penal', 'not', 'January', 'underwent', 'comic', 'they', 'Alongside', 'relating', 'to', 'squad', 'than', 'top', 'Sakimoto', '@-@', 'other', 'limited', 'such', 'military', 'assigned', 'unaltere', 'from', 'It', 'newcomers', 'Japan', 'release', 'something', 'HP', 'directly', 'returned', 'expanded', 'animation', 'which', 'localized', 'compatible', 'II', 'call', 'once', 'runs', 'serving', 'very', 'critics', 'content', 'Hitoshi', 'games', 'done', 'unvoiced', 'sub', 'health', 'by', 'standard', 'when', '\"', 'found', 'love', 'two', 'making', 'After', 'Action', 'commonly', 'speech', 'Media.Vision', 'text', 'Gallia', 'higher', 'happens', 'manga', 'granted', 'their', 'unlocked', 'will', 'Portable', 'low', '2011', 'told', 'lit', 'remain', 'take', 'field', 'same', 'received', 'would', 'black', 'May', 'has', 'Japanese', 'opening', '4', 'character', 'portraits', 'a', 'Valkyira', 'approach', '2014', 'While', 'Each', 'game', 'November', 'some', '.', 'referred', 'Potentials', 'fusion', 'sales', 'maps', 'depending', 'Sega', 'simulation', 'Due', 'Battlefield', 'where', 'first', 'Imperial', 'sealed', 'members', 'nine', 'designer', 'specific', 'third', 'sung', 'enemy', 'characters', 'mission', 'As', 'secret', 'met', 'one', 'select', 'Released', 'battlefield', 'portion', 'player', 'gradually', 'missions', 'book', 'distance', 'both', 'turns', 'only', ':', 'Nameless', 'each', 'return', 'per', 'at', 'original', 'story', '=', 'location', 'elements', 'Second', 'video', 'but', 'different', 'minor', 'around', 'customized', 'act', 'parallel', 'expense', 'as', 'multiple', 'attacks', 'occurs', 'entries', 'series', 'began', 'role', 'follows', 'team', 'downloadable', 'Character', 'along']\n"
     ]
    }
   ],
   "source": [
    "text = open('wikitext-2-raw/wiki.train.raw', 'r', encoding='utf8').read()\n",
    "text = text[0:4000]\n",
    "text = text.split()\n",
    "print('text length in numbers of characters:', len(text))\n",
    "chars = list(set(text))\n",
    "print(chars)\n",
    "VOCAB_SIZE = len(chars)\n",
    "SEQ_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_char = {index: char for index, char in enumerate(chars)}\n",
    "char_to_index = {char: index for index, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(text)//SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE))\n",
    "y = np.zeros((len(text)//SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE))\n",
    "\n",
    "for i in range(0, len(text)//SEQ_LENGTH):\n",
    "    X_sequence = text[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_index = [char_to_index[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    \n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_index[j]] = 1\n",
    "    X[i] = input_sequence\n",
    "    \n",
    "    y_sequence = text[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_index = [char_to_index[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    \n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_index[j]] = 1\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(500, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(1):\n",
    "    model.add(LSTM(500, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=50, verbose=1, nb_epoch=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
